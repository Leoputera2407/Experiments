{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==1.4.0\n",
    "!pip install transformers==2.9.0\n",
    "!pip install pytorch_lightning==0.7.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference with any question as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/huggingface/transformers/issues/4411\n",
    "import torch\n",
    "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
    "import tensorflow_hub as hub\n",
    "from rouge import Rouge \n",
    "from typing import List, Dict\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import sacrebleu\n",
    "import re\n",
    "import sys\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-07 14:22:43.387 | INFO     | __main__:<module>:1 - Processing the utterances now...\n",
      "2020-07-07 14:22:43.391 | INFO     | __main__:<module>:87 - Finished cleaning the utterances...\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Processing the utterances now...\")\n",
    "\n",
    "def load_slots_dict()-> Dict[str,str]:\n",
    "    \"\"\"\n",
    "    RETURNS\n",
    "    -------\n",
    "        (dict of string): a list of all slots that we've encountered before\n",
    "    \"\"\"\n",
    "    try:\n",
    "        slots_dict ={}\n",
    "        with open('known_slots.txt', 'r', encoding='utf8') as f:\n",
    "            for row in f:\n",
    "                SPLIT_TOKEN = ' <equals> '\n",
    "                slot, placeholder  = row.split(SPLIT_TOKEN)\n",
    "                slots_dict[slot] = placeholder.rstrip(\"\\n\")\n",
    "        return slots_dict\n",
    "    except:\n",
    "        logger.warning('known_slots.txt not found. Please specify the instance of the slots!')\n",
    "        return None\n",
    "    \n",
    "raw_sent= []\n",
    "try:\n",
    "    with open('sample_utterances.txt', 'r', encoding='utf8') as f:\n",
    "        for sent in f:\n",
    "            raw_sent.append(sent)\n",
    "except:\n",
    "    logger.warning(\"Please provide sample_utterances.txt.... Exitting now\")\n",
    "    sys.exit(1)\n",
    "        \n",
    "slots = set()\n",
    "for sent in raw_sent:\n",
    "    get_slots = re.findall(r'{(.*?)}', sent)\n",
    "    slots.update(get_slots)\n",
    "\n",
    "known_slot_dict = load_slots_dict()\n",
    "\n",
    "#If can't find load_slots_dict\n",
    "if not known_slot_dict:\n",
    "    file1 = open(\"known_slots.txt\", \"a\")\n",
    "    for slot in slots:\n",
    "        known_slot_dict={}\n",
    "        placeholder = input(\"Teach me an instance of \" + slot + \":\")\n",
    "        known_slot_dict[slot] = str(placeholder)\n",
    "        file1.write(str(slot) + ' <equals> ' + str(placeholder) + '\\n')\n",
    "    file1.close()\n",
    "\n",
    "#Unpack slots that we already know into a set\n",
    "slots_known = {*known_slot_dict.keys()}\n",
    "\n",
    "#If there exists some unidentifiable slots\n",
    "if not slots.issubset(slots_known):\n",
    "    slots_seen = slots.intersection(slots_known)\n",
    "    unknown_slots = slots.difference(slots_seen)\n",
    "    file1 = open(\"known_slots.txt\", \"a\")\n",
    "    for slot in unknown_slots:\n",
    "        placeholder = input(\"Teach me an instance of \" + slot + \":\")\n",
    "        known_slot_dict[slot] = str(placeholder)\n",
    "        file1.write(str(slot) + ' <equals> ' + str(placeholder) + '\\n')\n",
    "    file1.close()\n",
    "        \n",
    "        \n",
    "def multiple_replace(known_slots_dict: Dict[str,str], text: str):\n",
    "    \"\"\"\n",
    "    Function takes a dictionary of known_slots (slots: placeholder) and replace everything in the text \n",
    "    that has the {slots} pattern with its placeholder.\n",
    "    Reference\n",
    "    ---------\n",
    "    https://stackoverflow.com/questions/15175142/how-can-i-do-multiple-substitutions-using-regex-in-python\n",
    "    \n",
    "    ARGS\n",
    "    ----\n",
    "        known_slots_dict: dictionary of known_slots (slots: placeholder)\n",
    "        text: raw sentence (with slots) to be replaced\n",
    "    \"\"\" \n",
    "    # Create a regular expression  from the dictionary keys\n",
    "    regex = re.compile(\"{(%s)}\" % \"|\".join(map(re.escape, known_slots_dict.keys())))\n",
    "    \n",
    "    # For each match, look-up corresponding value in dictionary\n",
    "    return regex.sub(lambda mo: known_slots_dict[mo.string[mo.start()+1:mo.end()-1]], text) \n",
    "\n",
    "\n",
    "# Replace slots in strings\n",
    "CLEAN_SEN = []\n",
    "for sent in raw_sent:\n",
    "    CLEAN_SEN.append(multiple_replace(known_slot_dict,sent))\n",
    "    \n",
    "logger.info(\"Finished cleaning the utterances...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-07 14:22:43.409 | INFO     | __main__:<module>:1 - Setupping up models to generate paraphrases...\n",
      "2020-07-07 14:22:49.195 | INFO     | __main__:<module>:13 - Generating paraphrases on cpu.Recommend GPU for speed, of course!\n",
      "2020-07-07 14:22:49.200 | INFO     | __main__:<module>:16 - Preparing USE Embedding...Might have to download...\n",
      "INFO:absl:Using /var/folders/3l/0t74styx5wz0y5tkfgsvhycwfc38wl/T/tfhub_modules to cache modules.\n",
      "2020-07-07 14:22:59.864 | INFO     | __main__:<module>:20 - Done preparing USE Embedding\n",
      "2020-07-07 14:22:59.864 | INFO     | __main__:<module>:34 - Generating Paraphrase now\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1dd70ebd36e46e28cf794959a730e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-07 14:22:59.882 | INFO     | __main__:<module>:65 - Generating for utterance 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT SENTENCE : What is the sales of the title for period?\n",
      "PARAPRHASES :\n",
      "n°0 : What are the sales of the title for period?\n",
      "n°1 : What is the sales of the title for period?\n",
      "n°2 : What are the sales of the title during a period?\n",
      "n°3 : What are the sales of title for period?\n",
      "n°4 : How much sales does a title for period do?\n",
      "n°5 : What are the sales of the title in period?\n",
      "n°6 : What are the sales of a title for period?\n",
      "n°7 : What is the sales of title for period?\n",
      "n°8 : What are sales of the title for period?\n",
      "n°9 : What are sales of title for period?\n",
      "n°10 : What is the sales of a title for period?\n",
      "n°11 : What are sales of titles of period?\n",
      "n°12 : What are sales of a title for period?\n",
      "n°13 : What is the sale of the title for period?\n",
      "n°14 : How much are the sales of the title for period?\n",
      "n°15 : What is the sale of title for period?\n",
      "n°16 : How does the sales of a title of period?\n",
      "n°17 : What is the sale of a title for period?\n",
      "n°18 : How much are sales of title for period?\n",
      "n°19 : How does the sales of title for period?\n",
      "n°20 : How many sales of the title period?\n",
      "n°21 : How are sales of title for period?\n",
      "n°22 : How do you calculate the sales of a title for period?\n",
      "n°23 : How much is the sale of the title for period?\n",
      "n°24 : How is the sales of the title for period?\n",
      "n°25 : How is sales of a title for period?\n",
      "n°26 : How can we calculate sales of the title for period?\n",
      "n°27 : What are the sales of a title?\n",
      "n°28 : What is the sales of title?\n",
      "n°29 : What are the sales of the title?\n",
      "n°30 : What is the sales of a title?\n",
      "n°31 : What is the sales of the title?\n",
      "n°32 : How did the sales of the title for period?\n",
      "n°33 : How much revenue does a title generate during period?\n",
      "n°34 : How much sales did a name get for a period?\n",
      "n°35 : How many people are sold of a title in period?\n",
      "n°36 : How do you calculate the sales of the title?\n",
      "n°37 : What is the sale of the title?\n",
      "n°38 : How do I know the sales of the title?\n",
      "n°39 : How does the title get used? What is the sale of the title?\n",
      "n°40 : How can I sell the title for period?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Setupping up models to generate paraphrases...\")\n",
    "def set_seed(seed):\n",
    "  torch.manual_seed(seed)\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5_paraphrase')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(\"Generating paraphrases on {device}.Recommend GPU for speed, of course!\", device=device)\n",
    "model = model.to(device)\n",
    "\n",
    "logger.info(\"Preparing USE Embedding...Might have to download...\")\n",
    "#USE Embedder\n",
    "url = \"https://tfhub.dev/google/universal-sentence-encoder-large/4\"\n",
    "embed = hub.load(url)\n",
    "logger.info(\"Done preparing USE Embedding\")\n",
    "\n",
    "\n",
    "#Beam-search config\n",
    "MAX_SEQ_LEN = 256\n",
    "# Number of Paraphrases you want to generate\n",
    "NB_GENERATED = 200\n",
    "# Top N to keep\n",
    "TOP_TO_KEEP = 50\n",
    "#TOP_P (values bwn 0-1): threshold to keep token for nucleus sampling\n",
    "TOP_P = 0.90\n",
    "TOP_K = 75\n",
    "\n",
    "\n",
    "logger.info(\"Generating Paraphrase now\")\n",
    "#Put in proper format\n",
    "INPUT_SEN = []\n",
    "for sent in CLEAN_SEN:\n",
    "    INPUT_SEN.append(\"paraphrase: \" + sent + \" </s>\")\n",
    "\n",
    "def get_n_best_para(input_sentence: str, paraphrases: List[str], top_n: int = 1) -> List[str]:\n",
    "    \"\"\"\n",
    "    RETURNS\n",
    "    -------\n",
    "        (list of strings): top n paraphrases that are most semantically similar (using USE embeddings) and most\n",
    "            different structurally (using L-Rouge) to the input_sentence\n",
    "    \"\"\" \n",
    "    rouge = Rouge() \n",
    "    rouge_scrs = [1- rouge.get_scores(input_sentence, para)[0]['rouge-l']['f'] for para in paraphrases]\n",
    "    \n",
    "    #NOTE: Measure similarity using inner-product on USE embedding.\n",
    "    #enc_input_sentence, *enc_paraphrases = self.embed([input_sentence] + paraphrases)\n",
    "    enc_input_sentence = embed([input_sentence])\n",
    "    enc_paraphrases = embed(paraphrases)\n",
    "    MEANING_DIV_RATIO = 0.85\n",
    "    scored_paraphrases = [\n",
    "        (paraphrase, np.inner(enc_input_sentence['outputs'].numpy(), enc_paraphrase)[0] * MEANING_DIV_RATIO + score * (1-MEANING_DIV_RATIO))\n",
    "        for (paraphrase, enc_paraphrase, score) in zip(paraphrases, enc_paraphrases['outputs'].numpy(),rouge_scrs)\n",
    "    ]\n",
    "    #Sort on meaning, then diversity\n",
    "    top_n_paraphrases = sorted(scored_paraphrases, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    return [x[0] for x in top_n_paraphrases]\n",
    "\n",
    "para_list =[]\n",
    "for idx, text in tqdm(enumerate(INPUT_SEN)):\n",
    "    logger.info(\"Generating for utterance {}\", idx+1)\n",
    "    encoding = tokenizer.encode_plus(text,pad_to_max_length=True, return_tensors=\"pt\")\n",
    "    input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "    # https://huggingface.co/transformers/model_doc/t5.html?highlight=generate#overview\n",
    "    # https://huggingface.co/transformers/main_classes/model.html?highlight=generate#transformers.PreTrainedModel.generate\n",
    "    beam_outputs = model.generate(\n",
    "        input_ids=input_ids, attention_mask=attention_masks,\n",
    "        do_sample=True,\n",
    "        max_length=MAX_SEQ_LEN,\n",
    "        early_stopping=True,\n",
    "        top_k=TOP_K,\n",
    "        top_p=TOP_P,\n",
    "        num_return_sequences=NB_GENERATED\n",
    "    )\n",
    "    paraphrases =[]\n",
    "    for beam_output in beam_outputs:\n",
    "        sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
    "        if sent.lower() != text.lower() and sent not in paraphrases:\n",
    "            paraphrases.append(sent)\n",
    "            \n",
    "    top_para = get_n_best_para(CLEAN_SEN[idx], paraphrases, TOP_TO_KEEP)\n",
    "    print(\"INPUT SENTENCE :\", CLEAN_SEN[idx])\n",
    "    print(\"PARAPRHASES :\")\n",
    "    for i, paraphrase in enumerate(top_para):\n",
    "        print(\"n°%d : %s\" % (i, paraphrase))\n",
    "    para_list.append(paraphrases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the sales of {game}?\n",
      "--------\n",
      "What is the sales of {game} for {timeInterval}?\n",
      "--------\n",
      "What are the sales of {game} for {timeInterval}?\n",
      "--------\n",
      "What are the sales of {game} for {timeInterval}?\n",
      "--------\n",
      "What is the sale of {game} for {timeInterval}?\n",
      "--------\n",
      "What is the sale of {game} for {timeInterval}?\n",
      "--------\n",
      "How is the sales of {game} for {timeInterval}?\n",
      "--------\n",
      "How does the sales of {game} for {timeInterval}?\n",
      "--------\n",
      "What is the sales of {game} for {timeInterval}?\n",
      "--------\n",
      "What is the sale of {game}?\n",
      "--------\n",
      "What are the sales of {game} for {timeInterval}?\n",
      "--------\n",
      "What is the sales of {game} for {timeInterval}?\n",
      "--------\n",
      "How many people are sold of {game} in {timeInterval}?\n",
      "--------\n",
      "How is sales of {game} for {timeInterval}?\n",
      "--------\n",
      "What is the sales of {game}?\n",
      "--------\n",
      "How much sales did a name get for {timeInterval}?\n",
      "--------\n",
      "How can we calculate sales of {game} for {timeInterval}?\n",
      "--------\n",
      "What are the sales of {game}?\n",
      "--------\n",
      "What are sales of {game} for {timeInterval}?\n",
      "--------\n",
      "What is the sales of {game}?\n",
      "--------\n",
      "What are sales of {game} for {timeInterval}?\n",
      "--------\n",
      "What are the sales of {game} in {timeInterval}?\n",
      "--------\n",
      "How do you calculate the sales of {game} for {timeInterval}?\n",
      "--------\n",
      "What are the sales of {game}?\n",
      "--------\n",
      "How much is the sale of {game} for {timeInterval}?\n",
      "--------\n",
      "What is the sale of {game} for {timeInterval}?\n",
      "--------\n",
      "How can I sell {game} for {timeInterval}?\n",
      "--------\n",
      "What are the sales of {game} during {timeInterval}?\n",
      "--------\n",
      "How did the sales of {game} for {timeInterval}?\n",
      "--------\n",
      "What are sales of {game} for {timeInterval}?\n",
      "--------\n",
      "What are sales of titles of {timeInterval}?\n",
      "--------\n",
      "How much are the sales of {game} for {timeInterval}?\n",
      "--------\n",
      "How do you calculate the sales of {game}?\n",
      "--------\n",
      "How do I know the sales of {game}?\n",
      "--------\n",
      "How does the sales of {game} of {timeInterval}?\n",
      "--------\n",
      "How much sales does {game} for {timeInterval} do?\n",
      "--------\n",
      "How much revenue does {game} generate during {timeInterval}?\n",
      "--------\n",
      "How much are sales of {game} for {timeInterval}?\n",
      "--------\n",
      "How does {game} get used? What is the sale of {game}?\n",
      "--------\n",
      "How are sales of {game} for {timeInterval}?\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import textacy\n",
    "def mult_repl_text(replace_dict: Dict[str,str], text: str):\n",
    "    \"\"\"\n",
    "    Function takes a dictionary of known_slots {noun clause: slot} and replace all noun clause in text into slots.\n",
    "    Reference\n",
    "    ---------\n",
    "    https://stackoverflow.com/questions/15175142/how-can-i-do-multiple-substitutions-using-regex-in-python\n",
    "    \n",
    "    ARGS\n",
    "    ----\n",
    "        replace_dict: dictionary of {noun_clause: slots} \n",
    "        text: raw sentence (with noun clauses) to be replaced\n",
    "    RETURNS\n",
    "    -------\n",
    "        (string): text with all noun clauses replaced to slots\n",
    "    \"\"\" \n",
    "    # Create a regular expression  from the dictionary keys\n",
    "    regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape,replace_dict.keys())))\n",
    "    \n",
    "    # For each match, look-up corresponding value in dictionary\n",
    "    return regex.sub(lambda mo: replace_dict[mo.string[mo.start():mo.end()]], text) \n",
    "\n",
    "nlp = spacy.load('en_core_web_md', parser=False)\n",
    "final_list = []\n",
    "for paraphrases in para_list:\n",
    "    for para in paraphrases:\n",
    "        dict_replace = {}\n",
    "        doc = nlp(para)\n",
    "        for nc in doc.noun_chunks: # use np instead of np.text\n",
    "            for slot in slots:\n",
    "                if nlp.vocab[known_slot_dict[slot]].similarity(nc) > 0.8:\n",
    "                    dict_replace[nc.text] = '{' + slot + '}'\n",
    "        if dict_replace:\n",
    "            cleaned_sent = mult_repl_text(dict_replace, para)\n",
    "            print (cleaned_sent)\n",
    "            print(\"--------\")\n",
    "            final_list.append(cleaned_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "target ={\n",
    "  \"metadata\": {\n",
    "    \"schemaVersion\": \"1.0\",\n",
    "    \"importType\": \"LEX\",\n",
    "    \"importFormat\": \"JSON\"\n",
    "  },\n",
    "  \"resource\": {\n",
    "    \"description\": \"intent description\",\n",
    "    \"name\": \"\",\n",
    "    \"version\": \"version number\",\n",
    "    \"fulfillmentActivity\": {\n",
    "      \"type\": \"ReturnIntent\"\n",
    "    },\n",
    "    \"sampleUtterances\": []\n",
    "  }\n",
    "}\n",
    "INTENT_NAME = \"Hello_World\"\n",
    "\n",
    "target[\"resource\"][\"name\"] = INTENT_NAME\n",
    "target[\"resource\"][\"sampleUtterances\"] = final_list\n",
    "json_out = json.dumps(target, indent=4)\n",
    "\n",
    "with open(f\"{INTENT_NAME}.json\", \"w\") as f: \n",
    "    f.write(json_out) \n",
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile(\"new_intent.zip\", \"w\") as newzip:\n",
    "        newzip.write(f\"{INTENT_NAME}.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "para",
   "language": "python",
   "name": "para"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
