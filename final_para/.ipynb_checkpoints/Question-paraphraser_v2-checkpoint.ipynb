{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==1.4.0\n",
    "!pip install transformers==2.9.0\n",
    "!pip install pytorch_lightning==0.7.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference with any question as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/huggingface/transformers/issues/4411\n",
    "import torch\n",
    "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
    "import tensorflow_hub as hub\n",
    "from rouge import Rouge \n",
    "from typing import List, Dict\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import sacrebleu\n",
    "import re\n",
    "import sys\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-06 14:40:42.104 | INFO     | __main__:<module>:1 - Processing the utterances now...\n",
      "2020-07-06 14:40:42.109 | INFO     | __main__:<module>:87 - Finished cleaning the utterances...\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Processing the utterances now...\")\n",
    "\n",
    "def load_slots_dict()-> Dict[str,str]:\n",
    "    \"\"\"\n",
    "    RETURNS\n",
    "    -------\n",
    "        (dict of string): a list of all slots that we've encountered before\n",
    "    \"\"\"\n",
    "    try:\n",
    "        slots_dict ={}\n",
    "        with open('known_slots.txt', 'r', encoding='utf8') as f:\n",
    "            for row in f:\n",
    "                SPLIT_TOKEN = ' <equals> '\n",
    "                slot, placeholder  = row.split(SPLIT_TOKEN)\n",
    "                slots_dict[slot] = placeholder.rstrip(\"\\n\")\n",
    "        return slots_dict\n",
    "    except:\n",
    "        logger.warning('known_slots.txt not found. Please specify the instance of the slots!')\n",
    "        return None\n",
    "    \n",
    "raw_sent= []\n",
    "try:\n",
    "    with open('sample_utterances.txt', 'r', encoding='utf8') as f:\n",
    "        for sent in f:\n",
    "            raw_sent.append(sent)\n",
    "except:\n",
    "    logger.warning(\"Please provide sample_utterances.txt.... Exitting now\")\n",
    "    sys.exit(1)\n",
    "        \n",
    "slots = set()\n",
    "for sent in raw_sent:\n",
    "    get_slots = re.findall(r'{(.*?)}', sent)\n",
    "    slots.update(get_slots)\n",
    "\n",
    "known_slot_dict = load_slots_dict()\n",
    "\n",
    "#If can't find load_slots_dict\n",
    "if not known_slot_dict:\n",
    "    file1 = open(\"known_slots.txt\", \"a\")\n",
    "    for slot in slots:\n",
    "        known_slot_dict={}\n",
    "        placeholder = input(\"Teach me an instance of \" + slot + \":\")\n",
    "        known_slot_dict[slot] = str(placeholder)\n",
    "        file1.write(str(slot) + ' <equals> ' + str(placeholder) + '\\n')\n",
    "    file1.close()\n",
    "\n",
    "#Unpack slots that we already know into a set\n",
    "slots_known = {*known_slot_dict.keys()}\n",
    "\n",
    "#If there exists some unidentifiable slots\n",
    "if not slots.issubset(slots_known):\n",
    "    slots_seen = slots.intersection(slots_known)\n",
    "    unknown_slots = slots.difference(slots_seen)\n",
    "    file1 = open(\"known_slots.txt\", \"a\")\n",
    "    for slot in unknown_slots:\n",
    "        placeholder = input(\"Teach me an instance of \" + slot + \":\")\n",
    "        known_slot_dict[slot] = str(placeholder)\n",
    "        file1.write(str(slot) + ' <equals> ' + str(placeholder) + '\\n')\n",
    "    file1.close()\n",
    "        \n",
    "        \n",
    "def multiple_replace(known_slots_dict: Dict[str,str], text: str):\n",
    "    \"\"\"\n",
    "    Function takes a dictionary of known_slots (slots: placeholder) and replace everything in the text \n",
    "    that has the {slots} pattern with its placeholder.\n",
    "    Reference\n",
    "    ---------\n",
    "    https://stackoverflow.com/questions/15175142/how-can-i-do-multiple-substitutions-using-regex-in-python\n",
    "    \n",
    "    ARGS\n",
    "    ----\n",
    "        known_slots_dict: dictionary of known_slots (slots: placeholder)\n",
    "        text: raw sentence (with slots) to be replaced\n",
    "    \"\"\" \n",
    "    # Create a regular expression  from the dictionary keys\n",
    "    regex = re.compile(\"{(%s)}\" % \"|\".join(map(re.escape, known_slots_dict.keys())))\n",
    "    \n",
    "    # For each match, look-up corresponding value in dictionary\n",
    "    return regex.sub(lambda mo: known_slots_dict[mo.string[mo.start()+1:mo.end()-1]], text) \n",
    "\n",
    "\n",
    "# Replace slots in strings\n",
    "CLEAN_SEN = []\n",
    "for sent in raw_sent:\n",
    "    CLEAN_SEN.append(multiple_replace(known_slot_dict,sent))\n",
    "    \n",
    "logger.info(\"Finished cleaning the utterances...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-06 14:40:42.126 | INFO     | __main__:<module>:1 - Setupping up models to generate paraphrases...\n",
      "2020-07-06 14:40:46.987 | INFO     | __main__:<module>:13 - Generating paraphrases on cpu.Recommend GPU for speed, of course!\n",
      "2020-07-06 14:40:46.993 | INFO     | __main__:<module>:16 - Preparing USE Embedding...Might have to download...\n",
      "INFO:absl:Using /var/folders/3l/0t74styx5wz0y5tkfgsvhycwfc38wl/T/tfhub_modules to cache modules.\n",
      "2020-07-06 14:40:59.764 | INFO     | __main__:<module>:20 - Done preparing USE Embedding\n",
      "2020-07-06 14:40:59.765 | INFO     | __main__:<module>:34 - Generating Paraphrase now\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4322c583bbd4485daa5ad70d09b9835f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-06 14:40:59.786 | INFO     | __main__:<module>:64 - Generating for utterance 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT SENTENCE : What is the sales of the title for period?\n",
      "PARAPRHASES :\n",
      "n°0 : What are the sales of the title for period?\n",
      "n°1 : What is the sales of the title for period?\n",
      "n°2 : What are the sales of title for period?\n",
      "n°3 : What is the sales of title for period?\n",
      "n°4 : What are sales of the title for period?\n",
      "n°5 : What is the sales of a title for period?\n",
      "n°6 : How does title sales for period?\n",
      "n°7 : What is the sale of the title in period?\n",
      "n°8 : What is the sale of the title for period?\n",
      "n°9 : What is the sale of title for period?\n",
      "n°10 : How many is sales of the title for period?\n",
      "n°11 : How is the sale of a title for period?\n",
      "n°12 : How do we calculate sales of title for period?\n",
      "n°13 : How is the sales of the title for period?\n",
      "n°14 : What is the sales of title?\n",
      "n°15 : What are the sales of the title?\n",
      "n°16 : What is the sales of the title?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Setupping up models to generate paraphrases...\")\n",
    "def set_seed(seed):\n",
    "  torch.manual_seed(seed)\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5_paraphrase')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(\"Generating paraphrases on {device}.Recommend GPU for speed, of course!\", device=device)\n",
    "model = model.to(device)\n",
    "\n",
    "logger.info(\"Preparing USE Embedding...Might have to download...\")\n",
    "#USE Embedder\n",
    "url = \"https://tfhub.dev/google/universal-sentence-encoder-large/4\"\n",
    "embed = hub.load(url)\n",
    "logger.info(\"Done preparing USE Embedding\")\n",
    "\n",
    "\n",
    "#Beam-search config\n",
    "MAX_SEQ_LEN = 256\n",
    "# Number of Paraphrases you want to generate\n",
    "NB_GENERATED = 50\n",
    "# Top N to keep\n",
    "TOP_TO_KEEP = 50\n",
    "#TOP_P (values bwn 0-1): threshold to keep token for nucleus sampling\n",
    "TOP_P = 0.90\n",
    "TOP_K = 75\n",
    "\n",
    "\n",
    "logger.info(\"Generating Paraphrase now\")\n",
    "#Put in proper format\n",
    "INPUT_SEN = []\n",
    "for sent in CLEAN_SEN:\n",
    "    INPUT_SEN.append(\"paraphrase: \" + sent + \" </s>\")\n",
    "\n",
    "def get_n_best_para(input_sentence: str, paraphrases: List[str], top_n: int = 1) -> List[str]:\n",
    "    \"\"\"\n",
    "    RETURNS\n",
    "    -------\n",
    "        (list of strings): top n paraphrases that are most semantically similar (using USE embeddings) and most\n",
    "            different structurally (using L-Rouge) to the input_sentence\n",
    "    \"\"\" \n",
    "    rouge = Rouge() \n",
    "    rouge_scrs = [1- rouge.get_scores(input_sentence, para)[0]['rouge-l']['f'] for para in paraphrases]\n",
    "    \n",
    "    #NOTE: Measure similarity using inner-product on USE embedding.\n",
    "    #enc_input_sentence, *enc_paraphrases = self.embed([input_sentence] + paraphrases)\n",
    "    enc_input_sentence = embed([input_sentence])\n",
    "    enc_paraphrases = embed(paraphrases)\n",
    "    MEANING_DIV_RATIO = 0.85\n",
    "    scored_paraphrases = [\n",
    "        (paraphrase, np.inner(enc_input_sentence['outputs'].numpy(), enc_paraphrase)[0] * MEANING_DIV_RATIO + score * (1-MEANING_DIV_RATIO))\n",
    "        for (paraphrase, enc_paraphrase, score) in zip(paraphrases, enc_paraphrases['outputs'].numpy(),rouge_scrs)\n",
    "    ]\n",
    "    #Sort on meaning, then diversity\n",
    "    top_n_paraphrases = sorted(scored_paraphrases, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    return [x[0] for x in top_n_paraphrases]\n",
    "para_list =[]\n",
    "for idx, text in tqdm(enumerate(INPUT_SEN)):\n",
    "    logger.info(\"Generating for utterance {}\", idx+1)\n",
    "    encoding = tokenizer.encode_plus(text,pad_to_max_length=True, return_tensors=\"pt\")\n",
    "    input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "    # https://huggingface.co/transformers/model_doc/t5.html?highlight=generate#overview\n",
    "    # https://huggingface.co/transformers/main_classes/model.html?highlight=generate#transformers.PreTrainedModel.generate\n",
    "    beam_outputs = model.generate(\n",
    "        input_ids=input_ids, attention_mask=attention_masks,\n",
    "        do_sample=True,\n",
    "        max_length=MAX_SEQ_LEN,\n",
    "        early_stopping=True,\n",
    "        top_k=TOP_K,\n",
    "        top_p=TOP_P,\n",
    "        num_return_sequences=NB_GENERATED\n",
    "    )\n",
    "    paraphrases =[]\n",
    "    for beam_output in beam_outputs:\n",
    "        sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
    "        if sent.lower() != text.lower() and sent not in paraphrases:\n",
    "            paraphrases.append(sent)\n",
    "            \n",
    "    top_para = get_n_best_para(CLEAN_SEN[idx], paraphrases, TOP_TO_KEEP)\n",
    "    print(\"INPUT SENTENCE :\", CLEAN_SEN[idx])\n",
    "    print(\"PARAPRHASES :\")\n",
    "    for i, paraphrase in enumerate(top_para):\n",
    "        print(\"n°%d : %s\" % (i, paraphrase))\n",
    "    para_list.append(paraphrases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What\n",
      "What\n",
      "the sales\n",
      "the sales of the title for period\n",
      "the title\n",
      "the title for period\n",
      "period\n",
      "period\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'slots_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9954be8b081e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mknown_slot_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslot\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0mdict_replace\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mknown_slot_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslot\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmult_repl_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_replace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpara\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdict_replace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-9954be8b081e>\u001b[0m in \u001b[0;36mmult_repl_text\u001b[0;34m(replace_dict, text)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \"\"\" \n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Create a regular expression  from the dictionary keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mregex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(%s)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m\"|\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mescape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mslots_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# For each match, look-up corresponding value in dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'slots_dict' is not defined"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import textacy\n",
    "def mult_repl_text(replace_dict: Dict[str,str], text: str):\n",
    "    \"\"\"\n",
    "    Function takes a dictionary of known_slots {noun clause: slot} and replace all noun clause in text into slots.\n",
    "    Reference\n",
    "    ---------\n",
    "    https://stackoverflow.com/questions/15175142/how-can-i-do-multiple-substitutions-using-regex-in-python\n",
    "    \n",
    "    ARGS\n",
    "    ----\n",
    "        replace_dict: dictionary of {noun_clause: slots} \n",
    "        text: raw sentence (with noun clauses) to be replaced\n",
    "    RETURNS\n",
    "    -------\n",
    "        (string): text with all noun clauses replaced to slots\n",
    "    \"\"\" \n",
    "    # Create a regular expression  from the dictionary keys\n",
    "    regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape,replace_dict.keys())))\n",
    "    \n",
    "    # For each match, look-up corresponding value in dictionary\n",
    "    return regex.sub(lambda mo: replace_dict[mo.string[mo.start():mo.end()]], text) \n",
    "\n",
    "nlp = spacy.load('en_core_web_md', parser=False)\n",
    "for paraphrases in para_list:\n",
    "    for para in paraphrases:\n",
    "        dict_replace = {}\n",
    "        doc = nlp(para)\n",
    "        for nc in doc.noun_chunks: # use np instead of np.text\n",
    "            for np in [nc, doc[nc.root.left_edge.i:nc.root.right_edge.i+1]]:\n",
    "                print(np)\n",
    "            for slot in slots:\n",
    "                if nlp.vocab[known_slot_dict[slot]].similarity(np) > 0.8:\n",
    "                    dict_replace[np.text] = '{' + slot + '}'\n",
    "        print(mult_repl_text(dict_replace, para) if dict_replace else \"None\")\n",
    "        print(\"---------\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "para",
   "language": "python",
   "name": "para"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
